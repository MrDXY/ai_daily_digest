{
  "url": "https://campedersen.com/singularity",
  "payload": {
    "title": "The Singularity will occur on a Tuesday",
    "content": "\"Wait, the singularity is just humans freaking out?\" \"Always has been.\"\nEveryone in\nSan Francisco\nis talking about the singularity. At dinner parties, at coffee shops, at the OpenClaw meetup where Ashton Kutcher showed up for some reason. The conversations all have the same shape: someone says it's coming, someone says it's hype, and nobody has a number.\nThis seems like the wrong question. If things are accelerating (and they measurably are) the interesting question isn't\nwhether\n. It's\nwhen\n. And if it's accelerating, we can calculate\nexactly when\n.\nI collected five real metrics of AI progress, fit a hyperbolic model to each one independently, and found the one with genuine curvature toward a\npole\n. The date has\nmillisecond precision\n. There is a countdown.\n(I am aware this is\nunhinged\n. We're doing it anyway.)\nThe Data\nFive metrics, chosen for what I'm calling their\nanthropic significance\n(anthropic here in the Greek sense (\"pertaining to humans\"), not the company, though they appear in the dataset with suspicious frequency):\nMMLU scores\n: the SAT for language models\nTokens per dollar\n: cost collapse of intelligence (log-transformed, because the Gemini Flash outlier spans 150× the range otherwise)\nFrontier release intervals\n: shrinking gap between\n\"holy shit\"\nmoments\narXiv \"emergent\" papers\n(\ntrailing 12mo\n): field excitement, measured\nmemetically\nCopilot code share\n: fraction of code written by AI\nMMLU Benchmark Scores (% correct)\nGPT-3\nJun 2020\n43.9\nChinchilla\nMar 2022\n67.5\nGPT-4\nMar 2023\n86.4\nGemini Ultra\nDec 2023\n83.7\nClaude 3 Opus\nMar 2024\n86.8\nClaude 3.5 Sonnet\nJun 2024\n88.7\no1\nSep 2024\n90.8\nDeepSeek-R1\nJan 2025\n90.8\nGPT-4.5\nFeb 2025\n89.6\nGPT-4.1\nApr 2025\n90.2\nClaude Opus 4\nMay 2025\n88.8\nClaude Opus 4.5\nNov 2025\n90.8\nOutput Tokens per Dollar (tokens/$)\nGPT-3 (davinci)\nJun 2020\n16,667\nGPT-3.5 Turbo\nMar 2023\n500,000\nGPT-4\nMar 2023\n16,667\nGPT-4 Turbo\nNov 2023\n33,333\nGPT-4o\nMay 2024\n66,667\nClaude 3.5 Sonnet\nJun 2024\n66,667\nGemini 2.0 Flash\nDec 2024\n2,500,000\nDeepSeek-R1\nJan 2025\n456,621\nGPT-4.5\nFeb 2025\n6,667\nGemini 2.5 Pro\nMar 2025\n100,000\nGPT-4.1\nApr 2025\n125,000\nClaude Sonnet 4\nMay 2025\n66,667\nClaude Opus 4.5\nNov 2025\n40,000\nClaude Opus 4.6\nFeb 2026\n40,000\nFrontier Release Intervals (days)\nGPT-3 → ChatGPT\nNov 2022\n902\nChatGPT → GPT-4\nMar 2023\n104\nGPT-4 → Claude 2\nJul 2023\n119\n→ Claude 3 Opus\nMar 2024\n89\n→ o1\nSep 2024\n84\n→ Gemini 2.0\nDec 2024\n90\n→ DeepSeek-R1\nJan 2025\n40\n→ GPT-4.5\nFeb 2025\n38\n→ Gemini 2.5 Pro\nMar 2025\n26\n→ GPT-4.1\nApr 2025\n20\n→ Claude Sonnet 4\nMay 2025\n38\n→ Claude Opus 4.5\nNov 2025\n186\n→ Claude Opus 4.6\nFeb 2026\n73\nEach metric\nnormalized\nto\n[\n0\n,\n1\n]\n[0, 1]\n[\n0\n,\n1\n]\n. Release intervals inverted (shorter = better). Tokens per dollar log-transformed before normalizing (the raw values span\nfive orders of magnitude\n; without the log, Gemini Flash at 2.5M tokens/$ dominates the fit and everything else is noise). Each series keeps its own scale, no merging into a single ensemble.\nWhy Hyperbolic\nMost people extrapolate AI with\nexponentials\n. Wrong move!\nAn exponential\nf\n(\nt\n)\n=\na\ne\nb\nt\nf(t) = ae^{bt}\nf\n(\nt\n)\n=\na\ne\nb\nt\napproaches infinity only as\nt\n→\n∞\nt \\to \\infty\nt\n→\n∞\n. You'd be waiting forever. Literally.\nWe need a function that hits infinity at a\nfinite\ntime. That's the whole point of a singularity: a pole, a\nvertical asymptote\n,\nthe math breaking\n:\nx\n(\nt\n)\n=\nk\nt\ns\n−\nt\n+\nc\nx(t) = \\frac{k}{t_s - t} + c\nx\n(\nt\n)\n=\nt\ns\n​\n−\nt\nk\n​\n+\nc\nAs\nt\n→\nt\ns\n−\nt \\to t_s^-\nt\n→\nt\ns\n−\n​\n, the denominator goes to zero.\nx\n(\nt\n)\n→\n∞\nx(t) \\to \\infty\nx\n(\nt\n)\n→\n∞\n. Not a bug.\nThe\nfeature.\nx(t)\nx′(t)\nx″(t)\nx‴(t)\n2020\n2021\n2022\n2023\n2024\n2025\n2026\n2027\n2028\n2029\n2030\n2031\n0.00\n0.25\n0.50\n0.75\n1.00\nnormalized capability\nMMLU\nTokens/$\nRelease gaps\narXiv \"emergent\"\nCopilot code share\nsingularity\n95% CI\n52 data points across 5 metrics, fit to x_j(t) = k_j / (t_s − t) + c_j\nPolynomial\ngrowth (\nt\nn\nt^n\nt\nn\n) never reaches infinity at finite time. You could wait until\nheat death\nand\nt\n47\nt^{47}\nt\n47\nwould still be finite. Polynomials are for people who think AGI is \"decades away.\"\nExponential\ngrowth reaches infinity at\nt\n=\n∞\nt = \\infty\nt\n=\n∞\n. Technically a singularity, but an infinitely patient one. Moore's Law was exponential. We are no longer on Moore's Law.\nHyperbolic\ngrowth is what happens when the thing that's growing\naccelerates its own growth\n. Better AI → better AI research tools → better AI → better tools. Positive feedback with\nsupralinear dynamics\n. The singularity is real and finite.\nThe Fit\nThe procedure is straightforward, which should concern you.\nThe model fits a separate hyperbola to each metric:\ny\ni\n(\nj\n)\n=\nk\nj\nt\ns\n−\nt\ni\n+\nc\nj\ny_i^{(j)} = \\frac{k_j}{t_s - t_i} + c_j\ny\ni\n(\nj\n)\n​\n=\nt\ns\n​\n−\nt\ni\n​\nk\nj\n​\n​\n+\nc\nj\n​\nEach series\nj\nj\nj\ngets its own\nscale\nk\nj\nk_j\nk\nj\n​\nand\noffset\nc\nj\nc_j\nc\nj\n​\n. The singularity time\nt\ns\nt_s\nt\ns\n​\nis shared. MMLU scores and tokens-per-dollar have no business being on the same y-axis, but they can agree on when the pole is.\nFor each candidate\nt\ns\nt_s\nt\ns\n​\n, the per-series fits are\nlinear in\nk\nj\nk_j\nk\nj\n​\nand\nc\nj\nc_j\nc\nj\n​\n. The question is: which\nt\ns\nt_s\nt\ns\n​\nmakes the hyperbola fit best?\nHere's the thing nobody tells you about fitting singularities: most metrics don't actually have one. If you minimize total\nRSS\nacross all series, the best\nt\ns\nt_s\nt\ns\n​\nis always at infinity. A distant hyperbola\ndegenerates\ninto a line, and lines fit noisy data just fine. The \"singularity date\" ends up being whatever you set as the search boundary. You're finding the edge of your search grid, not a singularity.\nSo instead, we look for the real signal. For each series independently,\ngrid search\nt\ns\nt_s\nt\ns\n​\nand find the\nR²\npeak: the date where hyperbolic fits\nbetter\nthan any nearby alternative. If a series genuinely curves toward a pole, its R² will peak at some finite\nt\ns\nt_s\nt\ns\n​\nand then decline. If it's really just linear, R² will keep increasing as\nt\ns\n→\n∞\nt_s \\to \\infty\nt\ns\n​\n→\n∞\nand never peak. No peak, no signal, no vote!\nOne series peaks!\narXiv \"emergent\" (the count of AI papers about emergence) has a clear, unambiguous R² maximum. The other four are\nmonotonically\nbetter fit by a line. The singularity date comes from the one metric that's actually going hyperbolic.\nThis is more honest than forcing five metrics to average out to a date that none of them individually support.\nSame inputs → same date.\nDeterministic\n. The\nstochasticity\nis in the universe, not the model.\nThe Date\nThe Singularity Will Occur On\nTuesday, July 18, 2034\nat 02:52:52.170 UTC\nn = 52 across 5 series · 95% CI: Jan 2030–Jan 2041 (132.8 mo span)\nMMLU: R²=0.749\nTokens/$: R²=0.020\nRelease gaps: R²=0.291\narXiv \"emergent\": R²=0.926\nCopilot code share: R²=1.000\nThe fit\nconverged\n! Each series has its own\nR²\nat the shared\nt\ns\nt_s\nt\ns\n​\n, so you can see exactly which metrics the hyperbola captures well and which it doesn't. arXiv's R² is the one that matters. It's the series that actually peaked.\nThe 95% confidence interval comes from\nprofile likelihood\non\nt\ns\nt_s\nt\ns\n​\n. We slide the singularity date forward and backward until the fit degrades past an\nF-threshold\n.\nThe Countdown\n3077\ndays\n:\n21\nhours\n:\n54\nmin\n:\n14\nsec\n.\n130\nms\nuntil Tuesday, July 18, 2034 at 02:52:52.170 UTC\nSensitivity\nHow much does the date move if we drop one metric entirely?\nDrop-One-Out Sensitivity\nDropped\nNew t_s\nShift\nMMLU\nJul 2034\n+0.0 mo\nTokens/$\nJul 2034\n+0.0 mo\nRelease gaps\nJul 2034\n+0.0 mo\narXiv \"emergent\"\nFeb 2036\n+18.6 mo\nCopilot code share\nJul 2034\n+0.0 mo\nIf dropping a single series shifts\nt\ns\nt_s\nt\ns\n​\nby years, that series was doing all the work. If the shifts are zero, the dropped series never had a signal in the first place.\nThe table tells the story plainly: arXiv is doing all the work. Drop it and the date jumps to the search boundary (no remaining series has a finite peak). Drop anything else and nothing moves. They were never contributing to the date, only providing context curves at the shared\nt\ns\nt_s\nt\ns\n​\n.\nNote: Copilot has exactly 2 data points and 2 parameters (\nk\nk\nk\nand\nc\nc\nc\n), so it fits any hyperbola perfectly. Zero RSS, zero influence on\nt\ns\nt_s\nt\ns\n​\n. It's along for the ride!\nWhat\nt\ns\nt_s\nt\ns\n​\nActually Means\nThe model says\ny\n→\n∞\ny \\to \\infty\ny\n→\n∞\nat\nt\ns\nt_s\nt\ns\n​\n. But what does \"infinity\" mean for arXiv papers about emergence? It doesn't mean infinitely many papers get published on a Tuesday in 2034.\nIt means the model breaks.\nt\ns\nt_s\nt\ns\n​\nis the point where the current trajectory's curvature can no longer be sustained. The system either breaks through into something qualitatively new, or it saturates and the hyperbola was wrong. A\nphase transition marker\n, not a physical prediction.\nt\ns\nt_s\nt\ns\n​\nis the moment he looks down.\nBut here's the part that should unsettle you:\nthe metric that's actually going hyperbolic is human attention, not machine capability.\nMMLU, tokens per dollar, release intervals. The actual capability and infrastructure metrics. All linear. No pole. No singularity signal. The only curve pointing at a finite date is the count of papers about emergence. Researchers noticing and naming new behaviors.\nField excitement, measured memetically.\nThe data says: machines are improving at a constant rate. Humans are freaking out about it at an accelerating rate that accelerates its own acceleration.\nThat's a very different singularity than the one people argue about.\nThe Social Singularity\nIf\nt\ns\nt_s\nt\ns\n​\nmarks when the rate of AI surprises exceeds human capacity to process them, the interesting question isn't what happens to the machines. It's what happens to us.\nAnd the uncomfortable answer is:\nit's already happening.\nThe labor market isn't adjusting. It's snapping.\nIn 2025,\n1.1 million layoffs were announced\n. Only the sixth time that threshold has been breached since 1993. Over\n55,000 explicitly cited AI\n. But\nHBR found\nthat companies are cutting based on AI's\npotential\n, not its performance. The displacement is anticipatory. The curve doesn't need to reach the pole. It just needs to\nlook like it will\n.\nInstitutions can't keep up.\nThe EU AI Act's high-risk rules have\nalready been delayed to 2027\n. The US\nrevoked its own 2023 AI executive order\nin January 2025, then issued a new one in December trying to preempt state laws. California and Colorado are\ngoing their own way anyway\n. The laws being written today regulate 2023's problems. By the time legislation catches up to GPT-4, we're on GPT-7. When governments visibly can't keep up, trust doesn't erode. It\ncollapses\n. Global trust in AI has dropped to 56%.\nCapital is concentrating at dot-com levels.\nThe top 10 S&P 500 stocks (almost all AI-adjacent) hit\n40.7% of index weight\nin 2025, surpassing the dot-com peak. Since ChatGPT launched, AI-related stocks have captured\n75% of S&P 500 returns, 80% of earnings growth, and 90% of capital spending growth\n. The\nShiller CAPE\nis at\n39.4\n. The last time it was this high was\n1999\n. The money flooding in doesn't require AI to actually reach superintelligence. It just requires enough people to believe the curve keeps going up.\nPeople are losing the thread.\nTherapists are\nreporting a surge\nin what they're calling\nFOBO\n(Fear of Becoming Obsolete). The clinical language is striking: patients describe it as\n\"the universe saying, 'You are no longer needed.'\"\n60% of US workers\nbelieve AI will cut more jobs than it creates. AI usage is up 13% year-over-year, but confidence in it has\ndropped 18%\n.\nThe more people use it, the less they trust it.\nThe epistemics are cracking.\nLess than\na third of AI research is reproducible\n. Under 5% of researchers share their code. Corporate labs are publishing less. The gap between what frontier labs know and what the public knows is growing, and the people making policy are operating on information that's\nalready obsolete\n. The experts who testify before Congress contradict each other, because the field is moving\nfaster than expertise can form.\nThe politics are realigning.\nTIME\nis writing about populist AI backlash.\nForeign Affairs\npublished \"The Coming AI Backlash: How the Anger Economy Will Supercharge Populism.\"\nHuffPost\nsays AI will define the 2026 midterms. MAGA is\nsplitting\nover whether AI is pro-business or anti-worker. Sanders proposed a data center moratorium. The old left-right axis is buckling under the weight of a question it wasn't built to answer.\nAll of this is happening\neight years before\nt\ns\nt_s\nt\ns\n​\n. The social singularity is\nfront-running\nthe technical one. The institutional and psychological disruption doesn't wait for capabilities to go vertical. It starts as soon as the\ntrajectory\nbecomes legible.\nThe pole at\nt\ns\nt_s\nt\ns\n​\nisn't when machines become superintelligent. It's when humans lose the ability to make coherent collective decisions about machines. The actual capabilities are almost beside the point. The social fabric frays at the seams of attention and institutional response time, not at the frontier of model performance.\nCaveats\nThe date comes from one series.\narXiv \"emergent\" is the only metric with genuine hyperbolic curvature. The other four are better fit by straight lines. The singularity date is really \"the date when AI emergence research goes vertical.\" Whether field excitement is a\nleading indicator\nor a\nlagging one\nis the crux of whether this means anything.\nThe model assumes\nstationarity\n.\nLike assuming the weather will continue to be \"changing.\" The curve will bend, either into a\nlogistic\n(the hype saturates) or into something the model can't represent (genuine phase transition).\nt\ns\nt_s\nt\ns\n​\nmarks where the current regime can't continue, not what comes after.\nMMLU is hitting its ceiling.\nBenchmark saturation introduces a\nleptokurtic compression artifact\n. MMLU's low R² reflects this. The hyperbola is\nthe wrong shape\nfor saturating data.\nTokens per dollar is\nlog-transformed\n(values span five orders of magnitude)\nand\nnon-monotonic\n(GPT-4 cost more than 3.5; Opus 4.5 costs more than DeepSeek-R1). The cost curve isn't smooth: it's\nPareto advances\ninterspersed with\n\"we spent more on this one.\"\nFive metrics isn't enough.\nMore series with genuine hyperbolic curvature would make the date less dependent on arXiv alone. A proper study would add SWE-bench, ARC, GPQA, compute purchases, talent salaries. I used five because\nfive fits in a table\n.\nCopilot has two data points.\nTwo parameters, two points, zero\ndegrees of freedom\n, zero RSS contribution. The sensitivity analysis confirms it doesn't matter.\nConclusion\nReal data. Real model. Real date!\nThe math found one metric curving toward a pole on a specific day at a specific millisecond: the rate at which humans are discovering emergent AI behaviors. The other four metrics are linear. The machines are improving steadily.\nWe are the ones accelerating!\nThe social consequences of that acceleration (labor displacement, institutional failure, capital concentration, epistemic collapse, political realignment) are not predictions for 2034. They are descriptions of 2026. The singularity in the data is a singularity in human attention, and it is already exerting gravitational force on everything it touches.\nI see no reason to let\nepistemological humility\ninterfere with a\nperfectly good timer\n.\nSee you on the other side!\nCorrection (Feb 11, 2026)\nConnor Shepherd\npointed out that three of the MMLU scores were wrong. He's right. I'm sorry. Here's what happened:\nClaude 3.5 Sonnet:\nI wrote 88.7%. The actual score is\n88.3%\n. The 88.7% is GPT-4o's score. I mixed up the rows. In a post about rigorous data analysis. Yes.\no1:\nI wrote 90.8%. That's o1-preview. The full o1 scored\n91.8%\n.\nGPT-4.5:\nI wrote 89.6%. The actual score is\n90.8%\n.\nI have corrected all three values and rerun the fit. The new singularity date is:\nthe same date\n. To the millisecond. Because MMLU, as the sensitivity analysis already told you in the table above, has exactly zero influence on\nt\ns\nt_s\nt\ns\n​\n. It's a linear series with no hyperbolic peak. Correcting the scores is like fixing a typo in the passenger manifest of a plane that's already landed.\nI regret the errors. I do not regret the countdown.",
    "description": "",
    "url": "https://campedersen.com/singularity"
  },
  "cached_at": "2026-02-12T05:02:08.295487"
}