"""
Daily Insight Generator

å°†æ¯æ—¥æŠ“å–çš„å•æ¡æ‘˜è¦è¿›è¡Œ"äºŒæ¬¡ç‚¼é‡‘"ï¼Œç”Ÿæˆå…·æœ‰å…¨å±€æ´å¯ŸåŠ›çš„æ¯æ—¥æŠ€æœ¯ç®€æŠ¥ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- è¯»å–å½“å¤©æ‰€æœ‰ AI æ‘˜è¦
- èšåˆåˆ†æï¼Œè¯†åˆ«æ¨¡å¼ä¸å…³è”
- ç­›é€‰é«˜ä»·å€¼å†…å®¹
- ç”Ÿæˆæ¯’èˆŒé£æ ¼çš„æ¯æ—¥ç®€æŠ¥
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import date, datetime
from pathlib import Path
from typing import Any, Optional

import aiofiles

from ..core.config import AppConfig, get_output_dir, get_report_date_dir
from ..core.cache import AISummaryCache
from ..processor.ai_provider import AIProviderClient, AIProviderError

logger = logging.getLogger(__name__)


# ============================================
# Editor-in-Chief System Prompt
# ============================================

EDITOR_IN_CHIEF_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½æ¯’èˆŒä¸”æ´å¯ŸåŠ›æå¼ºçš„ç§‘æŠ€ä¸»ç¼–ã€‚ä½ çš„ç›®æ ‡æ˜¯ä»ä¸€å¤§å †æ‚ä¹±çš„æŠ€æœ¯æ–°é—»ä¸­ï¼ŒæŒ–æ˜å‡ºèƒŒåçš„"åº•å±‚é€»è¾‘"ã€‚

åŸåˆ™ï¼š
- æ‹’ç»ç¿»è¯‘è…”ï¼Œæ‹’ç»å®¢å¥—è¯
- å¦‚æœæŸä¸ªè¶‹åŠ¿æ˜¯åƒåœ¾ï¼Œè¯·ç›´æ¥æŒ‡å‡º
- å¦‚æœæŸä¸ªå°ä¼—é¡¹ç›®æœ‰æ½œåŠ›é¢ è¦†è¡Œä¸šï¼Œè¯·å¤§è‚†èµç¾
- å¯»æ‰¾ä¸åŒé¡¹ç›®ä¹‹é—´çš„"ååŒæ•ˆåº”"æˆ–"çŸ›ç›¾ç‚¹"

ä½ çš„æ–‡é£åº”è¯¥æ˜¯ï¼š
- çŠ€åˆ©ã€ç›´æ¥ã€æœ‰æ€åº¦
- åƒä¸€ä¸ªè€æ±Ÿæ¹–åœ¨èŒ¶ä½™é¥­ååæ§½è¡Œä¸šå…«å¦
- ä¸æ€•å¾—ç½ªäººï¼Œä½†è¨€ä¹‹æœ‰ç‰©
- ç”¨æ•°æ®å’Œé€»è¾‘è¯´è¯ï¼Œè€Œä¸æ˜¯ç©ºæ´çš„èµç¾æˆ–æ‰¹è¯„"""


INSIGHT_GENERATION_PROMPT = """## ä»»åŠ¡
ä½ éœ€è¦åˆ†æä»¥ä¸‹ {count} æ¡ä»Šæ—¥æŠ€æœ¯æ–°é—»æ‘˜è¦ï¼Œç”Ÿæˆä¸€ä»½å…·æœ‰å…¨å±€æ´å¯ŸåŠ›çš„æ¯æ—¥æŠ€æœ¯ç®€æŠ¥ã€‚

## è¾“å…¥æ•°æ®
ä»¥ä¸‹æ˜¯ä»Šå¤©çš„æ‰€æœ‰æŠ€æœ¯æ–°é—»æ‘˜è¦ï¼ˆJSON æ ¼å¼ï¼‰ï¼š

```json
{summaries_json}
```

## åˆ†ææ­¥éª¤
è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š

1. **èšåˆä¸èšç±»**ï¼šè¯†åˆ«è¿™äº›æ¡ç›®ä¹‹é—´çš„å…³è”ï¼ˆä¾‹å¦‚ï¼šæ˜¯å¦æœ‰å¤šä¸ªé¡¹ç›®éƒ½åœ¨è®¨è®ºåŒä¸€æŠ€æœ¯è¶‹åŠ¿ï¼Ÿï¼‰

2. **æ¨¡å¼è¯†åˆ«**ï¼š
   - ä»Šå¤©æœ‰å“ªäº›æŠ€æœ¯çƒ­ç‚¹ï¼Ÿ
   - ä¸åŒæ¥æºï¼ˆHN/GitHub/Lobstersï¼‰ä¹‹é—´æ˜¯å¦æœ‰å…±åŒå…³æ³¨çš„è¯é¢˜ï¼Ÿ
   - æœ‰å“ªäº›æ„æƒ³ä¸åˆ°çš„å…³è”ï¼Ÿ

3. **å†…å®¹ç­›é€‰**ï¼š
   - å‰”é™¤å¹³åº¸çš„ã€å¹¿å‘Šæ€§è´¨çš„æˆ–é‡å¤çš„é¡¹ç›®
   - åªä¿ç•™å‰ 10-15% çš„é«˜ä»·å€¼å†…å®¹
   - ç‰¹åˆ«å…³æ³¨é‚£äº›"çœ‹èµ·æ¥ä¸èµ·çœ¼ä½†å¯èƒ½å¾ˆé‡è¦"çš„é¡¹ç›®

4. **ç”ŸæˆæŠ¥å‘Š**ï¼šæŒ‰ç…§ä¸‹æ–¹æŒ‡å®šçš„æ ¼å¼ç”Ÿæˆæœ€ç»ˆå†…å®¹

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š

```json
{{
  "macro_trend": {{
    "title": "ä¸€å¥è¯æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20å­—ï¼‰",
    "content": "150å­—å·¦å³çš„æ·±åº¦è¯„è®ºï¼Œæ€»ç»“ä»Šå¤©çš„æŠ€æœ¯æƒ…ç»ªã€‚æ˜¯æ¿€è¿›ã€ç–²è½¯è¿˜æ˜¯åœ¨æ†‹å¤§æ‹›ï¼Ÿè¦æœ‰è§‚ç‚¹ï¼Œè¦çŠ€åˆ©ã€‚"
  }},
  "high_impact_picks": [
    {{
      "title": "é¡¹ç›®å",
      "url": "é¡¹ç›®é“¾æ¥",
      "source": "æ¥æºï¼ˆå¦‚ HN/GitHubï¼‰",
      "one_liner": "ä¸€å¥è¯æ€»ç»“ï¼ˆä¸è¶…è¿‡50å­—ï¼‰",
      "insight": "ä¸ºä»€ä¹ˆè¿™ç©æ„å„¿å€¼å¾—çœ‹ï¼Ÿå®ƒåŠ¨äº†è°çš„è›‹ç³•ï¼Ÿï¼ˆ50-100å­—ï¼‰",
      "score": åŸå§‹è¯„åˆ†
    }}
  ],
  "hidden_gems": [
    {{
      "title": "é¡¹ç›®å",
      "url": "é¡¹ç›®é“¾æ¥",
      "source": "æ¥æº",
      "description": "ä¸€å¥è¯æè¿°ï¼ˆä¸è¶…è¿‡50å­—ï¼‰",
      "comment": "åˆ«è¢« Star æ•°éª—äº†ï¼Œè¿™ä¸ªé¡¹ç›®çœŸæ­£è§£å†³çš„é—®é¢˜æ˜¯...ï¼ˆ50-100å­—ï¼‰"
    }}
  ],
  "community_pulse": {{
    "topic": "äº‰è®®è¯é¢˜æ ‡é¢˜",
    "summary": "æ€»ç»“ä»Šå¤©ç¤¾åŒºäº‰è®®æœ€å¤§çš„è¯é¢˜ï¼ˆ100-150å­—ï¼‰",
    "verdict": "ä½ ä½œä¸ºä¸»ç¼–çš„æœ€ç»ˆè£å†³ï¼ˆ50-100å­—ï¼Œè¦æœ‰æ€åº¦ï¼‰"
  }},
  "statistics": {{
    "total_analyzed": åˆ†æçš„æ€»æ¡ç›®æ•°,
    "sources_breakdown": {{"HN": æ•°é‡, "GitHub": æ•°é‡, ...}},
    "top_tech_stacks": ["æœ€å¸¸å‡ºç°çš„æŠ€æœ¯1", "æŠ€æœ¯2", "æŠ€æœ¯3"],
    "filtered_out_count": è¢«ç­›æ‰çš„ä½ä»·å€¼æ¡ç›®æ•°
  }}
}}
```

## æ³¨æ„äº‹é¡¹
- high_impact_picks æ•°é‡æ§åˆ¶åœ¨ 3-5 ä¸ª
- hidden_gems æ•°é‡æ§åˆ¶åœ¨ 2-3 ä¸ª
- å¦‚æœä»Šå¤©æ²¡æœ‰æ˜æ˜¾çš„ç¤¾åŒºäº‰è®®è¯é¢˜ï¼Œcommunity_pulse å¯ä»¥èŠèŠä½ è§‚å¯Ÿåˆ°çš„æœ‰è¶£ç°è±¡
- æ‰€æœ‰æ–‡å­—å¿…é¡»æ˜¯ä¸­æ–‡
- ä¿æŒæ¯’èˆŒä½†ä¸“ä¸šçš„é£æ ¼ï¼Œè¨€ä¹‹æœ‰ç‰©"""


# ============================================
# Data Models
# ============================================

@dataclass
class HighImpactPick:
    """é«˜å½±å“åŠ›é¡¹ç›®"""
    title: str
    url: str
    source: str
    one_liner: str
    insight: str
    score: float = 0.0


@dataclass
class HiddenGem:
    """é—ç é¡¹ç›®"""
    title: str
    url: str
    source: str
    description: str
    comment: str


@dataclass
class CommunityPulse:
    """ç¤¾åŒºåŠ¨æ€"""
    topic: str
    summary: str
    verdict: str


@dataclass
class MacroTrend:
    """å®è§‚è¶‹åŠ¿"""
    title: str
    content: str


@dataclass
class Statistics:
    """ç»Ÿè®¡æ•°æ®"""
    total_analyzed: int = 0
    sources_breakdown: dict[str, int] = field(default_factory=dict)
    top_tech_stacks: list[str] = field(default_factory=list)
    filtered_out_count: int = 0


@dataclass
class DailyInsight:
    """æ¯æ—¥æ´å¯ŸæŠ¥å‘Š"""
    date: str
    macro_trend: MacroTrend
    high_impact_picks: list[HighImpactPick]
    hidden_gems: list[HiddenGem]
    community_pulse: CommunityPulse
    statistics: Statistics
    generated_at: datetime = field(default_factory=datetime.now)

    def to_markdown(self) -> str:
        """è½¬æ¢ä¸º Markdown æ ¼å¼"""
        lines = [
            f"# ğŸš€ AI Daily Insight: {self.date}",
            "",
            f"## ğŸŒªï¸ å®è§‚é£æš´ (The Macro Trend)",
            f"> **{self.macro_trend.title}**",
            ">",
            f"> {self.macro_trend.content}",
            "",
            "## âš¡ æ ¸å¿ƒçªç ´ (High-Impact Picks)",
            "",
        ]

        for pick in self.high_impact_picks:
            score_display = f"è¯„åˆ†: {pick.score}" if pick.score else ""
            lines.extend([
                f"- **[{pick.title}]({pick.url})** `{pick.source}` {score_display}",
                f"  - {pick.one_liner}",
                f"  - **çŠ€åˆ©æ´å¯Ÿ**: {pick.insight}",
                "",
            ])

        lines.extend([
            "## ğŸ’ é—ç /å†·æ€è€ƒ (Hidden Gems & Skepticism)",
            "",
        ])

        for gem in self.hidden_gems:
            lines.extend([
                f"- **[{gem.title}]({gem.url})** `{gem.source}`",
                f"  - {gem.description}",
                f"  - **ç‚¹è¯„**: {gem.comment}",
                "",
            ])

        lines.extend([
            "## ğŸ—£ï¸ ç¤¾åŒºç«è¯å‘³ (Community Pulse)",
            "",
            f"### {self.community_pulse.topic}",
            "",
            self.community_pulse.summary,
            "",
            f"**ä¸»ç¼–è£å†³**: {self.community_pulse.verdict}",
            "",
            "---",
            "",
            "## ğŸ“Š æ•°æ®ç»Ÿè®¡",
            "",
            f"- åˆ†ææ¡ç›®: {self.statistics.total_analyzed}",
            f"- ç­›é™¤æ¡ç›®: {self.statistics.filtered_out_count}",
            f"- æ¥æºåˆ†å¸ƒ: {', '.join(f'{k}: {v}' for k, v in self.statistics.sources_breakdown.items())}",
            f"- çƒ­é—¨æŠ€æœ¯: {', '.join(self.statistics.top_tech_stacks)}",
            "",
            "---",
            "",
            f"> ğŸ¤– ç”± AI Daily Insight äº {self.generated_at.strftime('%Y-%m-%d %H:%M:%S')} ç”Ÿæˆ",
            "> ",
            "> æœ¬æŠ¥å‘Šä½¿ç”¨ LLM è¿›è¡ŒäºŒæ¬¡åˆ†æï¼Œè§‚ç‚¹ä»…ä¾›å‚è€ƒ",
        ])

        return "\n".join(lines)

    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "date": self.date,
            "macro_trend": {
                "title": self.macro_trend.title,
                "content": self.macro_trend.content,
            },
            "high_impact_picks": [
                {
                    "title": p.title,
                    "url": p.url,
                    "source": p.source,
                    "one_liner": p.one_liner,
                    "insight": p.insight,
                    "score": p.score,
                }
                for p in self.high_impact_picks
            ],
            "hidden_gems": [
                {
                    "title": g.title,
                    "url": g.url,
                    "source": g.source,
                    "description": g.description,
                    "comment": g.comment,
                }
                for g in self.hidden_gems
            ],
            "community_pulse": {
                "topic": self.community_pulse.topic,
                "summary": self.community_pulse.summary,
                "verdict": self.community_pulse.verdict,
            },
            "statistics": {
                "total_analyzed": self.statistics.total_analyzed,
                "sources_breakdown": self.statistics.sources_breakdown,
                "top_tech_stacks": self.statistics.top_tech_stacks,
                "filtered_out_count": self.statistics.filtered_out_count,
            },
            "generated_at": self.generated_at.isoformat(),
        }


# ============================================
# Daily Insight Generator
# ============================================

class DailyInsightGenerator:
    """
    æ¯æ—¥æ´å¯Ÿç”Ÿæˆå™¨

    è¯»å–å½“å¤©çš„ AI æ‘˜è¦ï¼Œé€šè¿‡ LLM è¿›è¡ŒäºŒæ¬¡åˆ†æï¼Œ
    ç”Ÿæˆå…·æœ‰å…¨å±€æ´å¯ŸåŠ›çš„æ¯æ—¥æŠ€æœ¯ç®€æŠ¥ã€‚
    """

    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            config: åº”ç”¨é…ç½®
        """
        self.config = config
        self._provider: Optional[AIProviderClient] = None

        # åˆå§‹åŒ–æ‘˜è¦ç¼“å­˜
        cache_dir = get_output_dir(config) / "cache" / "ai_summary"
        self._summary_cache = AISummaryCache(cache_dir, enabled=True)

    def _get_provider(self) -> AIProviderClient:
        """è·å– AI Provider"""
        if self._provider is None:
            self._provider = AIProviderClient(self.config)
        return self._provider

    async def load_summaries(self, target_date: Optional[date] = None) -> list[dict[str, Any]]:
        """
        åŠ è½½æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ‘˜è¦

        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©

        Returns:
            æ‘˜è¦åˆ—è¡¨
        """
        if target_date is None:
            target_date = date.today()

        cache_dir = self._summary_cache.cache_dir / target_date.isoformat()

        if not cache_dir.exists():
            logger.warning(f"No summary cache found for {target_date}")
            return []

        summaries = []
        for cache_file in cache_dir.glob("*.json"):
            try:
                async with aiofiles.open(cache_file, "r", encoding="utf-8") as f:
                    content = await f.read()
                    data = json.loads(content)

                    summary_data = data.get("summary", {})
                    source_item = summary_data.get("_source_item", {})

                    # æ„å»ºç»Ÿä¸€çš„æ‘˜è¦æ¡ç›®
                    entry = {
                        "title": source_item.get("title", ""),
                        "url": data.get("url", source_item.get("url", "")),
                        "source": source_item.get("source", "Unknown"),
                        "content_summary": summary_data.get("summary", ""),
                        "core_value": summary_data.get("core_value", ""),
                        "tech_stack": summary_data.get("tech_stack", []),
                        "recommendation": summary_data.get("recommendation", ""),
                        "score": summary_data.get("score", 0),
                        "stars": source_item.get("stars"),
                    }

                    # è¿‡æ»¤æ‰æ— æ•ˆæ¡ç›®
                    if entry["title"] and entry["content_summary"]:
                        summaries.append(entry)

            except Exception as e:
                logger.warning(f"Failed to load summary from {cache_file}: {e}")
                continue

        logger.info(f"Loaded {len(summaries)} summaries for {target_date}")
        return summaries

    async def generate_insight(
        self,
        summaries: list[dict[str, Any]],
        target_date: Optional[date] = None,
    ) -> DailyInsight:
        """
        ç”Ÿæˆæ¯æ—¥æ´å¯ŸæŠ¥å‘Š

        Args:
            summaries: æ‘˜è¦åˆ—è¡¨
            target_date: ç›®æ ‡æ—¥æœŸ

        Returns:
            DailyInsight å¯¹è±¡
        """
        if target_date is None:
            target_date = date.today()

        date_str = target_date.isoformat()

        if not summaries:
            logger.warning("No summaries to analyze")
            return self._create_empty_insight(date_str)

        # å‡†å¤‡è¾“å…¥æ•°æ®
        summaries_json = json.dumps(summaries, ensure_ascii=False, indent=2)

        # æ„å»º prompt
        prompt = INSIGHT_GENERATION_PROMPT.format(
            count=len(summaries),
            summaries_json=summaries_json,
        )

        provider = self._get_provider()

        try:
            # è°ƒç”¨ LLM ç”Ÿæˆæ´å¯Ÿ
            response = await provider.generate_text(
                prompt=prompt,
                system=EDITOR_IN_CHIEF_SYSTEM_PROMPT,
                max_tokens=4096,
                temperature=0.7,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„è¾“å‡º
            )

            # è§£æå“åº”
            insight = self._parse_insight_response(response, date_str)
            return insight

        except AIProviderError as e:
            logger.error(f"Failed to generate insight: {e}")
            raise

    def _parse_insight_response(self, response: str, date_str: str) -> DailyInsight:
        """è§£æ LLM å“åº”"""
        try:
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]

            data = json.loads(response.strip())

            # è§£æå„éƒ¨åˆ†
            macro_data = data.get("macro_trend", {})
            macro_trend = MacroTrend(
                title=macro_data.get("title", "ä»Šæ—¥æ— ç‰¹åˆ«è¶‹åŠ¿"),
                content=macro_data.get("content", ""),
            )

            high_impact_picks = [
                HighImpactPick(
                    title=p.get("title", ""),
                    url=p.get("url", ""),
                    source=p.get("source", ""),
                    one_liner=p.get("one_liner", ""),
                    insight=p.get("insight", ""),
                    score=p.get("score", 0),
                )
                for p in data.get("high_impact_picks", [])
            ]

            hidden_gems = [
                HiddenGem(
                    title=g.get("title", ""),
                    url=g.get("url", ""),
                    source=g.get("source", ""),
                    description=g.get("description", ""),
                    comment=g.get("comment", ""),
                )
                for g in data.get("hidden_gems", [])
            ]

            pulse_data = data.get("community_pulse", {})
            community_pulse = CommunityPulse(
                topic=pulse_data.get("topic", "ä»Šæ—¥ç¤¾åŒºæ— æ˜æ˜¾äº‰è®®"),
                summary=pulse_data.get("summary", ""),
                verdict=pulse_data.get("verdict", ""),
            )

            stats_data = data.get("statistics", {})
            statistics = Statistics(
                total_analyzed=stats_data.get("total_analyzed", 0),
                sources_breakdown=stats_data.get("sources_breakdown", {}),
                top_tech_stacks=stats_data.get("top_tech_stacks", []),
                filtered_out_count=stats_data.get("filtered_out_count", 0),
            )

            return DailyInsight(
                date=date_str,
                macro_trend=macro_trend,
                high_impact_picks=high_impact_picks,
                hidden_gems=hidden_gems,
                community_pulse=community_pulse,
                statistics=statistics,
            )

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse insight response as JSON: {e}")
            logger.debug(f"Response: {response[:500]}...")
            return self._create_empty_insight(date_str)

    def _create_empty_insight(self, date_str: str) -> DailyInsight:
        """åˆ›å»ºç©ºçš„æ´å¯ŸæŠ¥å‘Š"""
        return DailyInsight(
            date=date_str,
            macro_trend=MacroTrend(
                title="æ•°æ®ä¸è¶³",
                content="ä»Šæ—¥æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æã€‚",
            ),
            high_impact_picks=[],
            hidden_gems=[],
            community_pulse=CommunityPulse(
                topic="æ— ",
                summary="æ²¡æœ‰å‘ç°æ˜æ˜¾çš„ç¤¾åŒºè®¨è®ºçƒ­ç‚¹ã€‚",
                verdict="å»ºè®®å…³æ³¨æ›´å¤šä¿¡æ¯æºã€‚",
            ),
            statistics=Statistics(),
        )

    async def generate_and_save(
        self,
        target_date: Optional[date] = None,
        output_format: str = "both",
    ) -> tuple[DailyInsight, Path]:
        """
        ç”Ÿæˆå¹¶ä¿å­˜æ¯æ—¥æ´å¯ŸæŠ¥å‘Š

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            output_format: è¾“å‡ºæ ¼å¼ï¼Œ"markdown" / "json" / "both"

        Returns:
            (DailyInsight, è¾“å‡ºæ–‡ä»¶è·¯å¾„)
        """
        if target_date is None:
            target_date = date.today()

        date_str = target_date.isoformat()

        # åŠ è½½æ‘˜è¦
        summaries = await self.load_summaries(target_date)

        # ç”Ÿæˆæ´å¯Ÿ
        insight = await self.generate_insight(summaries, target_date)

        # ä¿å­˜æ–‡ä»¶
        output_dir = get_report_date_dir(self.config, date_str)
        output_dir.mkdir(parents=True, exist_ok=True)

        saved_path = None

        # ä¿å­˜ Markdown
        if output_format in ("markdown", "both"):
            md_path = output_dir / f"daily_insight_{date_str}.md"
            async with aiofiles.open(md_path, "w", encoding="utf-8") as f:
                await f.write(insight.to_markdown())
            logger.info(f"Saved Markdown insight to {md_path}")
            saved_path = md_path

        # ä¿å­˜ JSON
        if output_format in ("json", "both"):
            json_path = output_dir / f"daily_insight_{date_str}.json"
            async with aiofiles.open(json_path, "w", encoding="utf-8") as f:
                await f.write(json.dumps(insight.to_dict(), ensure_ascii=False, indent=2))
            logger.info(f"Saved JSON insight to {json_path}")
            if saved_path is None:
                saved_path = json_path

        return insight, saved_path

    async def close(self) -> None:
        """å…³é—­èµ„æº"""
        if self._provider:
            await self._provider.close()
            self._provider = None


# ============================================
# Factory Function
# ============================================

def create_daily_insight_generator(config: AppConfig) -> DailyInsightGenerator:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ¯æ—¥æ´å¯Ÿç”Ÿæˆå™¨

    Args:
        config: åº”ç”¨é…ç½®

    Returns:
        DailyInsightGenerator å®ä¾‹
    """
    return DailyInsightGenerator(config)

